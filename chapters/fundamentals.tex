\chapter{Grundlagen}
\label{sec:fundamentals}
\todo[color=blue!40]{Feedback zu Struktur des Literaturkapitels}\section{Software Qualitätssicherung}
\subsection{Motivation und Relevanz}

\todo{Evt. einleitende Worte...}
Der Funktionsumfang von Software stieg in den letzten fünzig Jahren enorm. Gleichzeitig bietet die Geschichte der Informatik viele Beispiele, die für die Notwendigkeit von Qualitätssicherung in der Softwareentwicklung sprechen. Ein sehr bildhaftes Beispiel der Folgen von fehlerhafter Software, ist die Selbstzerstörung der Ariane 5 Rakete im Jahr 1996 \cite{giese_warum_2002}. Das Trägheitsnavigationssystem wandelte eine 64-bit-Gleitkommazahl in eine Ganzzahl. Dieser Programmteil wurde schon in der Ariane 4 verwendet, nur war diese weitaus schubschwächer und der betroffene Sensor erzeugte viel kleinere Ergebnisse. Nur 36 Sekunden nach Start des Erstfluges, setzte also ein klassischer Überlauf ein und die Rakete aktivierte ihren Selbstzerstörungsmechanismus.
Ähnliches passierte bei der Raumsonde Mars Obiter der NASA. Diese war am 24. September 1999 gestartet und hätte 220 Millionen Kilometer später auf dem roten Planeten landen sollen. Kurz vor der Landung ging der Kontakt verloren, die Sonde zerschellte an der Oberfläche des Planeten. In diesem Fall war es kein Überlauf sondern ein Fehler bei den Maßeinheiten die den Steuerungsschub kontrollierten. Die Entwickler der NASA erwarteten in ihrem Code Zahlen in Form von Newton, während der Hersteller Lockheed Martin angloamerikanische Pfund lieferte.Durch Zufall fiel der Fehler während des gesamten Flugs nicht auf. \cite{thaller_software-test:_2002}
In keinem der beiden Vorfälle kamen Menschen zu Schaden, trotzdem waren die finanziellen Verluste enorm. Natürlich war die Komplexität dieser NASA-Projekte sehr hoch und wahrscheinlich nicht repräsentativ für Software die am Markt erhältlich ist, trotzdem wären beide Fehler durch Testing vermeidbar gewesen. Im Fall der Ariane 5 hätte es ausgereicht die Schnittstelle zum Steuercomputer mit Extremwerten zu testen. Man wäre schnell auf den Überlauf gestoßen und hätte die Umrechnung anpassen können. Auch Mars Orbiter hätte durch ausführliches Schnittstellen-Testing auf Basis von Verträgen, welche die beteiligten Software-Teams untereinander ausmachen, gerettet werden können.

\subsubsection{Der Zwang zu qualitativem Wachstum}
Die Qualität von Software erhöhte sich geschichtlich nicht im selben Maße wie ihre Funktionalität. Dafür werden von (Thaller)\cite{thaller_software-test:_2002}

Der Drang nach Wachstum bei modernen Programmen negiert die Erfolge die Unternehmen durch erhöhte Anstrengungen in der Qualitätssicherung feiern könnten. Die Zahl der Fehler wird weitläufig gesenkt,  gleichzeitig nimmt der Funktionsumfang der Programme massiv zu. Dieser Umstand rührt daher, dass ständig neue Käuferschichten gewonnen werden müssen, die wiederum neue Features fordern.
Software dringt in Gebiete vor die von analoger Technik dominiert wurde. Aeronautik, Medizin und Finanzwesen verlangen nach großen Programmpaketen, die potenziell viele Fehlerquellen mit weichreichenden Folgen enthalten.

\subsubsection{Komplexe Systeme führen zu Fehlern}
Von der Programmierung in Hochsprachen bis zur Ausführung auf der Hardware müssen unzählige Schichten korrekt ineinander greifen um das gewünschte Ergebnis hervorzubringen. 
Daher gilt:

\begin{quote}
Komplexe Systeme analytisch in begrenzer Zeit nur unvollständig erfassbar. Fehler sind damit zwangsläufig die Folge. \cite{vigenschow_objektorientiertes_2004}
\end{quote} „

Gründe wieso Fehler auftreten sind mannigfaltig. Aus menschlicher Sicht können Fehler auf drei Ebenen auftreten: \cite{vigenschow_objektorientiertes_2004}

\paragraph{Kommunikation}
Jegliche Art von Kommunikation ist Transformation \cite{shannon_mathematische_1976}. Dabei passieren diese Transformationen nicht nur bei der Kommunikation zwischen zwei Menschen sondern auch bei der Transformation von Sprache in Verständnis. Naturgemäß bleibt bei diesen Transformationen Informationsgehalt verloren, abhängig von verschiedenen Rahmenbedingungen manchmal sogar sehr viel, beispielsweise wenn Information in einer Sprache übermittelt wird, welche nicht die Muttersprache von beiden Kommunikationspartnern ist.
Im technischen Umfeld gibt es darum viele Standardbegriffe, die möglichst genau definiert sind. So soll der Informationsverlust eingeschränkt werden.
Weiters spielt sich ein nicht unerheblicher Teil der Kommunikation auf unterbewusster Ebene ab.

\paragraph{Fachlichkeit}
Kunden oder Auftraggeber sind naturgemäß Experten auf ihrem Gebiet. Sie wollen Software um ihre fachlichen Ziele effektiver verfolgen zu können. Dem Software-Entwickler fehlt dieses Fachwissen. Dem Entwickler fehlt dieses Fachwissen oft.
Der Kunde hat sehr detaillierte Vorstellungen der Software, ihm fehlt aber die Fähigkeit auf technischer und fachlicher Ebene zu abstrahieren. Dies ist eine der Hauptaufgaben des Requirements-Engineer. Genau an dieser Stelle ist die Gefahr groß, dass durch fehlendes fachliches Wissen wichtige Zusammenhänge übersehen werden oder unwichtigen Details zu viel Aufmerksamkeit geschenkt wird.
Außerdem sind die technischen Möglichkeiten nur eingeschränkt für den Kunden fassbar. Gerade Aufwandsschätzungen sind für Entwickler schon schwierig Das hat zur Folge, dass die Entwickler oft Alternativen anbieten müssen welche möglicherweise nicht den exakten Anforderungen entsprechen.

\paragraph{Komplexität}
Die Komplexität der Problemstellung bestimmt über Machbarkeit und Fehlerpotenzial. Seit Anbeginn der Informatik wird versucht Komplexität auf ein überschaubares Maß herunterzubrechen. Sei es durch Zerlegung in möglichst kleine Aufgaben, visuelle Darstellungsformen oder Abstraktion zu bekannten Programmiermustern.
Komplexität wird dadurch aber niemals vermindert, sondern nur versteckt bzw. anschaulicher gemacht.


\subsection{Softwarequlität und Standards}
Der Begriff Qualität kann auf vielfältige Art und Weise definiert werden. Jeder Mensch hat ein gewisses intuitives Verständnis dafür. Bezogen auf verschiedene Anwendungsfelder assoziiert ein Jeder andere Merkmale eines Objekts mit Qualität.

\begin{quote}
Entscheidend ist, was die Anspruchsteller vor dem Hintergrund ihrer Anforderungen wahrnehmen und für wichtig halten. Während die rational bedingte Sachqualität mit naturwissenschaftlich-technischen Methoden messbar ist, bereitet die reproduzierbare Messung der Anmutungsqualität Probleme.\cite{markgraf_definition_2015}
\end{quote}

Im Kontext der Software-Entwicklung verbinden Entwickler und Projektleiter mit dem Begriff der Qualität verschiedene Inhalte.\cite{hoffmann_software-qualitat_2013} Aus diesem Grund wurde bereits mehrfach versucht, eine einheitliche Definition für den Begriff Qualität zu finden. Die, inzwischen überholte DIN-ISO-Norm 9126 \footnote{ISO 9126: Software Quality \url{http://www.iso.org/iso/catalogue_detail.htm?csnumber=22749}} definiert Softwarequalität wie folgt:

\begin{quote}
Software-Qualität ist die Gesamtheit der Merkmale und Merkmalswerte eines Software-Produkts, die sich auf dessen Eignung beziehen, festgelegte Erfordernisse zu erfüllen.
\end{quote}

Diese Definition unterstreicht, dass der Begriff Software-Qualität eine multikausale Größe beschreibt.\cite{hoffmann_software-qualitat_2013} Vor dem Hintergrund, des sich rasant entwickelnden Gebiets der Software-Entwicklung, gibt es nun eine stark überarbeitete Version dieser ISO-Norm. Die Normenreihe ISO/IEC 25000 umfasst nun über ein dutzend Standards die sich sehr detailliert mit der Thematik auseinandersetzen. Dazu zählen unter anderem Leitfäden zu Planung und Management, Metriken zur Qualitätsmessung und Anforderungen an Datenqualität. Im Wesentlichen definiert ISO/IEC 25010 \footnote{ISO/IEC 25010: Systems and Software Quality Requirements and Evaluation (SQuaRE) \url{http://www.iso.org/iso/home/store/catalogue_ics/catalogue_detail_ics.htm?csnumber=35733}} eine Reihe vielschichtiger Kriterien, welche als Bausteine der Software-Qualität verstanden werden können.

\paragraph{Funktionalität (Functionality, Capability)} Dieses Qualitätsmerkmal beschreibt, in welchem Maß ein Software-System den ihm zugeschriebenen Funktionsumfang tatsächlich erfüllt. Funktionale Fehler entstehen aus den verschiedensten Umständen. Möglich sind Fehler die passieren wenn Anforderungen auf eine nicht beabsichtigte Art und Weise implementiert werden. Andererseits lassen sich funktionale Fehler auch oft auf unvollständige oder nicht vorhandene Spezifikationen zurückführen. Äußere Faktoren wie Zeitmangel oder zwischenmenschliche Unstimmigkeiten haben einen besonders negativen Einfluss auf die häufigste Art von funktionalen Fehlern: Klassische Implementierungsfehler (sogenannte ``bugs''). Diese sind auch das Hauptaugenmerk der Methoden und Techniken der Software-Qualitätssicherung. Weil funktionale Fehler so allgegenwärtig sind, wird der Begriff der Software-Qualität häufig auf dieses eine Kriterium reduziert wahrgenommen.

\paragraph{Laufzeit (Performance)} Jedes Software-System unterliegt gewissen Laufzeitanforderungen. Oft wird diesen aber bei der Formulierung der Anforderungen weniger Beachtung, als funktionalen Anforderungen, geschenkt. Laufzeitanforderungen können bei Nichtbeachtung sehr lange Zeit unentdeckt bleiben, sich dann aber zu ernstzunehmenden Problemen entwickeln.\\
Im Bereich der Echtzeitsysteme unterliegen alle Operationen Zeitanforderungen, die entweder im statistischen Mittel (weiche Echtzeit) oder in jedem Einzelfall (harte Echtzeit) zwingend erfüllt werden müssen. \cite{hoffmann_software-qualitat_2013}

\paragraph{Zuverlässigkeit (Reliability)} In sicherheitskritischen Anwendungen kann sich ein Systemversagen direkt auf die Unversehrtheit der beteiligten Personen auswirken. Zuverlässigkeit ist aber eng mit anderen Kriterien gekoppelt und kann (und soll) nicht als einzelnes Ziel erreicht werden.

\paragraph{Wartbarkeit (Maintainability)} Wartbarkeit und Langlebigkeit sind zentrale Qualitätsmerkmale moderner Software-Systeme. \cite{rombach_design_2009} In vielen Fällen hört die Projektplanung bei der Inbetriebnahme der Applikation auf und ignoriert die Notwendigkeit, nachträglich Anpassungen zu machen und Fehler zu beheben.

\paragraph{Transparenz (Transparency)} Der Grad der Transparenz beschreibt wie die nach außen sichtbare Funktionalität, intern umgesetzt wurde. Eine zentrale Fragestellung ist: ``Lässt sich durch Betrachtung des Programms von außen (aus Blackbox-Sicht \todo{Ref zu Blackbox-Beschreibung}) auf die internen Vorgänge des Codes schließen?''. Wenn diese Durchsichtigkeit gegeben ist, spricht man von hoher Transparenz. Ein Programm kann geforderte Funktionalität aber auf unendlich viele Art und Weisen bedienen (man denke an Problemstellungen der theoretischen Informatik, wie die Church-Turing These\footnote{Die Church-Turing These trifft Aussagen über die Mächtigkeit von Programmiersprachen. \cite{hoffmann_theoretische_2011} Da sich unendlich viele Programmiersprachen definieren lassen, kann man darauf schließen, dass sich ein Programm auf unendlich viele Art und Weisen schreiben lässt.}) Die Transparenz trifft daher keine Aussage über die Richtigkeit des Programms. Statistisch gesehen nimmt die Transparenz eines Software-Systems im Zuge seiner Weiterentwicklung kontinuierlich ab.\cite{hoffmann_software-qualitat_2013} Man sprich davon, dass Software altert oder von Software-Entropie. Der Grad der Transparenz ist daher eng mit \textit{Wartbarkeit} und \textit{Testbarkeit} gekoppelt. 

\paragraph{Übertragbarkeit (Portability)} Übertragbarkeit beschreibt die Einfachheit bestehende Software auf andere Umgebungen oder Plattformen zu übertragen. Dabei ist Ausschlaggebend wieviel Aufwände in die Umstrukturierung und Umprogrammierung des Software-Systems fließen müssen. Wie so oft, müssen bei der Betrachtung von Übertragbarkeit, zum Zeitpunkt des Entwurfs der Software, Kompromisse eingegangen werden. Software wird vielfach nur für wenige geplante Zielplattformen designed und entwickelt, muss dann im weiteren Verlauf aber für andere Plattformen erweitert werden.

\paragraph{Testbarkeit (Testability)} Die Testbarkeit beschreibt wie gut oder schlecht ein Software-System testbar ist. Fehler sollen zeitnah gefunden und behebbar sein (Wartbarkeit). Testbarkeit wird schon zum Entwurfszeitpunkt bestimmt (design for test). Es geht darum, ob ein Programm geeignete Schnittstellen für das Testing bietet (sozusagen Zugriff auf seine Interna zulässt). Gängige Beispiele sind Logging-Funktionalitäten oder Schnittstellen die Benutzerinteraktionen simulieren.

Die Kriterien \textit{Funktionalität, Laufzeit, Zuverlässigkeit} und \textit{Benutzbarkeit} sind unmittelbar nach außen sichtbar und repräsentieren die Qualiätssicht des Benutzers. Folglich beeinflussen diese Kriterien die initiale Kaufentscheidung massiv. Die Kriterien \textit{Transparenz, Übertragbarkeit, Wartbarkeit} und \textit{Testbarkeit} offenbaren sich dem Benutzer üblicherweise viel später. Sie entscheiden über den langfristigen Erfolg und wie sich ein Software-Produkt am Markt hält.

\subsubsection{Zusammenhänge und Kompromisse} 
Nach Evaluation all dieser Kriterien kann eine Aussage über die Qualität von Software getroffen werden. Sie beeinflussen sich gegenseitig. Am Beispiel von \textit{Laufzeit} und \textit{Übertragbarkeit} lassen sich diese Zusammenhänge gut erkennen. Hochperfomante Software-Systeme nutzen viele Spezialitäten der verwendeten Programmiersprache und der Plattform auf dem sie betrieben werden. Wenn aus fundamentalen Bausteinen wie Architektur und Design keine weiteren Leistungssteigerungen gewonnen werden können, muss auf solche ``Adaptions-Tricks'' zurückgegriffen werden um den entscheidenden Vorsprung gegenüber Konkurrenzprodukten zu gewinnen. Die Übertragbarkeit eines Systems definiert sich aber wesentlich durch die ausschließliche Verwendungen von Konstrukten die in möglichst vielen Umgebungen verfügbar ist. Plattformabhängigkeiten müssten daher wieder generalisiert werden, was mit Aufwänden verbunden ist.\\
Deshalb ist es auch nicht möglich, ein Software-System zu entwickeln, das alle genannten Qualitätskriterien gleichermaßen erfüllt. Solche Aussagen sind aber nicht nur auf Software zu beschränken. Es handelt sich um sehr allgemeine Gesetzmäßigkeiten, die bereits in der Forschung zur klassischen Evolutionstheorie aufgedeckt wurden.\cite{hoffmann_software-qualitat_2013} Dies erklärt auch, weshalb viele dieser Zusammenänge intuitiv Sinn machen. Nicht alle Qualitätskriterien beeinflussen gleich viele andere Kriterien. Auch positive Effekte sind erkennbar. Eine hohe \textit{Testbarkeit} beeinflusst \textit{Zuverlässigkeit} positiv. Abbildung \ref{fig:korrelationsmatrix} zeigt die Vereinbarkeit/Unvereinbarkeit der Qualitätskriterien, die in der Softwareentwicklung eine Rolle spielen. Es wird deutlich welche Qualitäten kompromitiert werden müssen wenn andere im Projekt einen höheren Stellenwert haben. Gleichzeitig wird verdeutlicht, dass verschiedene Kriterien positive Auswirkungen aufeinander haben.

\begin{figure}[h] 
  \centering
     \includegraphics[width=0.9\textwidth]{figures/korrelationsmatrix.png}
  \caption{Die Korrelationsmatrix über die genannten Qualitätskriterien\cite{hoffmann_software-qualitat_2013}}
  \label{fig:korrelationsmatrix}
\end{figure}

Aus dem Projektmanagement ist das magische Dreieck bekannt (siehe Abbildung \ref{fig:magic_triangle}), das sich unmittelbar aus den eben genannten Korrelationen ableiten lässt. Die äußeren Eckpunkte des Dreiecks geben an, in welchem Maß die Parameter \textit{Zeit}, \textit{Kosten} und \textit{Qualität} erfüllt sind. Der Flächeninhalt des Dreiecks soll konstant sein, was veranschaulicht, dass jede Erhöhung eines Parameters die anderen beiden beeinflusst. Dieses Dreieck wird nicht nur durch die gewählten Entwicklungstechnologien und Requirements beeinflusst, sondern auch durch die Teststrategie. Welche Testmethoden und Werkzeuge gewählt werden, beeinflusst alle drei Parameter.

\begin{figure}[h] 
  \centering
     \includegraphics[width=0.7\textwidth]{figures/magic_triangle.png}
  \caption{Dieses Dreieck veranschaulicht wie sich die Qualitätsparameter Qualität, Zeit und Kosten gegenseitig beeinflussen. Die Fläche des Dreiecks bleibt fixiert, während die Seitenlängen verändert werden.}
  \label{fig:magic_triangle}
\end{figure}


\subsection{Testprozess}
\subsection{Teststufen}
\subsubsection{Klassisches Vorgehen}
\subsubsection{Agiles Testen}
\subsection{Regressionstests und Testautomatisierung}

\section{Modellbasiertes Testen}
\label{sec:mbt}
\subsection{Definition}
Im allgemeinsten Sinn, werden im modellbasierten Testing Testfälle aus Modellen abgeleitet, die das Sollverhalten eines Software-Systems beschreiben. \cite{sensler_testautomatisierung_2011}\\

In \cite{utting_practical_2007} werden vier verschiedene Herangehensweisen zusammenfassend als modellbasiertes Testen definiert:

\begin{itemize}
\item Generierung von Testdaten aus einem Domänenmodell
\item Generierung von Testfällen aus einem Umgebungsmodell
\item Generierung von Testfällen aus einem Verhaltensmodell
\item Generierung von Test-Skripts aus einem abstrakten Test
\end{itemize}

Die Autoren legen den Schwerpunkt auf die generativen Aspekte. Weniger Aufmerksamkeit wird dem vorausgehenden Schritt geschenkt: Die Modellierung der genannten Modelle. \cite{rossner_basiswissen_2010} nennt folgende  zentralen Merkmale des modelbasierten Testings:

\begin{itemize}
\item Die zu testende Software, ihre Umgebung oder der Test, wird über Modelle betrachtet.
\item Diese Modelle konzentrieren sich in abstrahierter Form auf besondere Eigenschaften des SUT (meist auf dessen Verhalten).
\item Diese Modelle können entweder eigenständig erstellt werden oder aus Entwicklungsmodellen abgeleitet werden.
\item Mit Testdaten und technologischen Adaptern kombiniert, bilden diese Modelle die Basis generierter Testfälle.
\end{itemize}

Dies führt zur pragmatischen Definition von modellbasiertem Testing:

\begin{quote}
Modellbasiertes Testen umfasst mindestens einen der beiden folgenden Aspekte: Tests modellieren oder Tests aus Modellen generieren.
\end{quote}

\subsection{Vorteile des Modellbasierten Testings}
In diesem Abschnitt sollen die Vorteile des MBT gegenüber anderen Testmethoden, auch anhand von Publikationen und Fallstudien, erläutert werden.

\paragraph{Anzahl der gefundenen Fehler} Mehrere Fallstudien belegen die Konkurrenzfähigkeit von MBT. Repräsentativ für die Automobilindustrie hat BMW mehrere modellbasierte Testsuites im produktiven Einsatz verglichen.\cite{pretschner_one_2005} SUT war ein gängiger Netzwerk Controller. Ein Teil der Testsuiten wurde manuell aber auf Basis eines Modells des SUT entwickelt, während der andere Teil automatisch anhand von Modellen generiert wurde. Beide Arten von Testsuiten fanden mehr Spezifikationsfehler als die traditionelle Testsuiten (diese wurden direkt von der Spezifikation in Prosa abgeleitet). Bei der Anzahl der gefundenen Programmierfehler, schnitten die modellbasierten Tests nicht besser ab. Testfälle die von der Spezifikation abgeleitet wurden, manuell entwickelte modellbasierte Tests und automatisch generierte modellbasierte Tests lagen gleichauf. Diese Fallstudie ist weiters sehr interessant, weil nicht nur manuell entworfene Modelle als Basis der Testfallgenerierung eingesetzt wurden. Die Autoren ließen einen Teil der Modelle, durch Ableitung vom SUT und dem Einsatz von Regeln, automatisch generieren.\\ \todo{Verweis zu automatisch generierten Testmodellen...} \\
IBM verglich MBT im Java-Umfeld mit konventionellen Testmethoden.\cite{farchi_using_2002} Dabei fanden sie heraus, dass ihre MBT Testsuiten nicht nur eine höhere Code-Abdeckung garantierten, sondern auch mehr Programmierfehler aufdeckten. Die Aufwände für die Erstellung dieser Modelle war dabei vergleichbar mit der Entwicklung der skriptbasierten Testsuite. Um die Modelle überschaubar groß zu halten, wurde nur das externe Verhalten der getesteten Features modelliert.\\
Viele MBT-Tools konzentrieren sich auf den Einsatz mit Embedded-Technologien. Es scheint, dass MBT in dieser Domäne seine ganze Stärke ausspielen kann. So berichten Legeard und Peureux in mehreren Publikationen, dass die von Modellen abgeleiteten Testfälle,  beim Test von \textit{smart card}-Software, ein Vielfaches von den manuell gefundenen Fehlern auffinden konnten.\cite{legeard_generation_2001}\\
Während viele Ergebnisse darauf hindeuten, dass MBT gleich viele oder sogar mehr Fehler aufdeckt (\cite{dalal_model-based_1999}, \cite{legeard_generation_2001}) als manuelle Tests, hängen diese Ergebnisse stark von den Fähigkeiten des Testers ab. Vor allem die Bestimmung der Testauswahlkriterien, hat viel Einfluss auf die Qualität der Testfälle.\cite{utting_practical_2007}

\paragraph{Zeit- und Kostenaufwände} MBT kann zu Zeitersparnissen führen, wenn die aufgewendete Zeit für das Modelldesign und Wartung, plus die Orchestrierung der Testfallgenerierung, geringer ist als die Erstellung und Wartung einer manuellen bzw. automatischen Testsuite, plus deren Ausführung.\\
In mehreren Fallstudien stellten die Autoren eine Zeitersparnis gegenüber manuellen Tests fest.\cite{farchi_using_2002}\cite{prenninger_mbt_2005}\cite{pretschner_one_2005} Ähnlich wie es bei einer Einführung von automatisierten Skripttests der Fall ist, zeichnet sich eine Zeitersparnis durch MBT aber erst später ab. Die initialen Aufwände für die Modellierung aber auch die Einführung eines ungewohnten Workflows und die neuartige Sicht auf das System, erfordern Zeit.\\
Nicht unerwähnt bleiben, soll ein Teilergebnis des AGEDIS Projekts \footnote{AGEDIS war ein zeitlich auf 3 Jahre beschränktes Projekt der Europäischen Union und mehreren Industriepartnern. Ziel war die Evaluation von Model-based testing Tools und die Entwicklung eines ``Standard-Workflows''. Siehe \url{http://www.agedis.de}}. Dabei kamen die Autoren zum Schluss, dass die Zeitersparnisse der modellbasierten Testfallgenerierung durch die hohen Einarbeitungsaufwände in das Testausführungswerkzeug, zunichte gemacht wurden.\cite{craggs_agedis_2003}\\
Ein Faktor der in vielen Fallstudien und Fachtexten nicht beachtet wird, ist die mögliche Zeitersparnis durch MBT nachdem die Testfälle ausgeführt wurden, also zum Zeitpunkt der Analyse der Ergebnisse. Da modellbasierte Testfälle eine konsistentere Form als manuell erstellte Skripts aufweisen, ist es einfacher gefundene Fehler nachzuvollziehen. Wenn beim Modelldesign sogar auf eine explizite Verknüpfung von Komponenten und Spezifikationen geachtet wurde (``requirement traceability'') erleichtert dies das Auffinden der Fehlerquelle weiter. Manche MBT-Tools sind sogar in der Lage mehrere (darunter auch die kürzesten) Sequenzen aufzuzeigen, die zum Fehlerfall führen. Diese Zusatzinformationen führen zu einem insgesamt schnelleren Gesamtprozess.\cite{utting_practical_2007}

\paragraph{Testqualität} Der Prozess des manuellen Testfalldesigns wird im seltensten Fall dokumentiert und ist daher nicht genau reproduzierbar. Welche Menge von Testfällen eine bestimmte Spezifikation abdecken ist schwer nachvollziehbar. Über eine längeren Zeitraum kann dies zu Unklarheiten führen und erschwert die Wartung.\cite{utting_practical_2007} MBT macht diesen Prozess systematisch, da die Testfallgeneratoren auf präzise definierte Algorithmen und Heuristiken zurückgreifen. Die Effizienz einer Testfallsuite lässt sich dadurch messen. Beispielsweise kann eine Aussage darüber getroffen werden, wieviele und welche Testfälle nötig waren um einen bestimmten Fehler aufzudecken. Eine vergleichbare Aussage mit manuellem Testfalldesign zu machen, ist mit hohen Aufwänden verbunden, da keine automatische Generierung der Testfälle erfolgt.\\
Wenn ein aussagekräftiges Modell erst generiert wurde, lassen sich mittels MBT-Testfallgeneratoren eine extrem hohe Menge an Testfällen erzeugen. Die Kosten für die Erzeugung der Testfälle betragen, ganz im Gegensatz zum manuellen Testfalldesign, nur die Zeit die der Testfallgenerator zur Berechnung braucht.

\paragraph{Spezifikationsfehler}
Fehler in der Spezifikation eines Software-Systems sind die Folgeschwersten. \cite{utting_practical_2007} Durch ihr frühes Auftreten bauen sich im schlimmsten Fall Architektur- und Designentscheidungen auf ihnen auf. Gleichzeitig ist es sehr einfach Spezifikationsfehler zu korrigieren wenn sie früh erkannt werden.\\
Durch den frühen Einsatz von Modellen (entweder im Rahmen von modellgetriebener Entwicklung oder eben durch den Einsatz von modellbasiertem Testen) ist der Requirements-Engineer gezwungen gewisse Unklarheiten zu eliminieren, die in Prosa-Texten nicht auffallen würden. Durch diese Erhöhung des Detailgrades in der Spezifikationsphase kommen fragen auf wie: `Wie soll das System mit einer ungültigen Eingabe umgehen?', `Können diese zwei Konditionen gleichzeitig wahr/falsch sein?', `Wie soll ein korrupter Workflow neugestartet werden?'\\
Bei Microsoft, wo MBT zum Testing von Kommunikationsprotokollen eingesetzt wurde, kamen bei der Modellierung doppelt soviele Design- und Spezifikationsfehler als Implementationsfehler zum Vorschein.\cite{stobie_model_2005} Bei frühzeitigem Einsatz von MBT, bewegt sich ein großer Teil der Aktivitäten des Testers vom reinen `Abfangen' der Fehler am Schluss des Entwicklungszyklus, zu vorausschauendem Modellieren.

\subsection{Modellkategorien}
Im Feld der modellgetriebenen Entwicklung und des modellbasierten Testens wird grundsätzlich zwischen drei verschiedenen Modellkategorien unterschieden.

\paragraph{Umgebungsmodelle} stellen den Ausschnitt der Domäne dar, wo das zu testende System platziert wird oder ist.
\paragraph{Systemmodelle} beschreiben das SUT in statischer und dynamischer Hinsicht. Sie stellen dar aus welchen Komponenten das SUT zusammengesetzt ist, welche Eigenschaften diese haben und wie diese miteinander kommunizieren. 
\paragraph{Testmodelle} dienen als Grundlage für die Generierung von Testfällen, basiernd auf Spezifikations- und Entwurfsdokumenten. Daher enthalten sie auch oftmals Teile von Umgebungs- und Systemmodellen. Weiters beschreiben sie den Ablauf der zu generierenden Testfälle. Möglich ist die Angabe darüber, welche Eingaben das SUT erhalten soll und welche Ausgaben bzw. Reaktionen erwartet werden.

\subsection{Der MBT Prozess}
Model-based Testing automatisiert, einer nachvollziehbaren Strategie folgend \todo{Ref zu Pfadabdeckung usw}, die Erstellung der detaillierten Testfälle (Testscripts).
Im Detail erstellt der Test-Designer ein abstraktes Modell des SUT (welches gewisse Eigenschaften haben muss, siehe \todo{Ref zu Eigenschaften des Testmodells}). Dieses abstrakte Testmodell wird einem Tool übergeben welches die Testfälle generiert. Die Zeit einen Testfall zu designen wird durch den Einsatz von MBT reduziert. Außerdem befähigt die Erstellung eines einzelnen Modells, die automatische Generierung einer Vielzahl von Testfällen. Der Testfall-Designer muss dazu am Tool nur die Testauswahlkriterien verändern. \cite{utting_practical_2007} Der Prozess kann also in 5 Schritten dargestellt werden (siehe Abbildung \ref{fig:mbt_prozess}):

\begin{enumerate}
\item Das SUT und/oder seine Umgebung modellieren.
\item Abstrakte Tests vom Testmodell werden generiert.
\item Die Abstrakten Testfälle werden konkretisiert, also ausführbar gemacht.
\item Ausführen der Testfälle auf dem SUT.
\item Analyse der Ergebnisse nachdem die Testfälle auf dem SUT durchgelaufen sind.
\end{enumerate}

\begin{figure}[h] 
  \centering
     \includegraphics[width=0.9\textwidth]{figures/MBT_Prozess.png}
  \caption{Der MBT Prozess \cite{utting_practical_2007}}
  \label{fig:mbt_prozess}
\end{figure}

Die Schritte 4 und 5 sind Teil jeder Testmethode. Schritt 3 ist Teil einer jeden automatisierten Testmethode. Im Bereich des skritpbasierten Testings wird dieser Schritt von den eingesetzten Tools, so weit wie möglich in den Hintergrund gerückt \todo{Ref zu Skriptbasierten Tests}. Oft gestaltet sich die Übersetzung von abstrakten zu ausführbaren Testfällen aber wesentlich aufwendiger als beworben. (\todo{Irgendeine ref...}).
Die Schritte 1 und 2 unterscheiden MBT also von anderen Testmethoden. Das Modell aus Schritt 1 soll eine abstrakte Darstellung des SUT bzw. seiner Umgebung sein. Das bedeutet es werden nur die, für das Testing relevanten Teile modelliert. Dieses Modell muss demnach viel simpler und kleiner als das reale SUT ausfallen. Außerdem kann es nötig sein, das Modell zu annotieren um informelle Requirements abzubilden, die ansonsten mit der Abstraktion verloren gehen würden. Das Modell sollte nach Fertigstellung verfiziert werden, um formale Korrektheit zu gewährleisten. Dafür bieten viele Modellierungssprachen geeignete Werkzeuge \cite{kaneiwa_consistency_2006}. Außerdem gibt es interaktive Werkzeuge, die das Verhalten eines Modells grafisch darstellen und so das debuggen vereinfachen.\\
Der zweite Schritt, die Generierung von Testfällen aus dem Modell, wird maßgeblich von den gewählten Testauswahlkritereien beeinflusst. Mittels verschiedensten Traversierungsstrategien können aus einem Modell grundsätzlich eine unendliche Menge von Testfällen erzeugt werden \cite{utting_practical_2007}. Die Testauswahlkriterien dienen daher der kontrollierten Einschränkung dieser Menge von Testfällen \todo{Ref. siehe Pfadabdeckung usw}. Der Output dieses Schritts ist also ein Set von abstrakten Testfällen, welche jeweils eine Menge von Operationen definieren die auf dem SUT ausgeführt werden sollen. Da das Modell aber eine vereinfachte Abstraktion des SUT ist, fehlen diesen Operationen die Implementierungsdetails. Diese abstrakten Testfälle sind daher noch nicht ausführbar.\\
Im dritten Schritt werden die abstrakten Testfälle in ausführbare Testskripts verwandelt. An dieser Stelle werden die verschiedensten Ansätze verfolgt. Manche Werkzeuge nehmen als erstes eine Transformation in eine anderen Datenstruktur vor. Das Open Source Werkzeug GraphWalker\footnote{Open Source MBT Tool GraphWalker http://graphwalker.org/} wandelt das Modell erst in einen gerichteten Graphen, bevor aus diesem ein Set von JUnit-Testfällen erzeugt wird. Andere Tools, wie beispielsweise die Implementierung von \cite{pinheiro_model-based_2013}, serialisieren die Modelle erst in ein allgemeineres Format (in diesem Fall XMI\footnote{XML Metadata Interchange Format http://www.omg.org/spec/XMI/}) bevor Testskripts für ein verbreitetes Tool erzeugt werden. Ein Vorteil der sich aus diesem schichtartigen Vorgehen ergibt, ist die Unabhängigkeit von Testplattformen. Solange sich die Logik der Applikation zwischen verschiedenen Plattformen (oder Versionen in anderen Programmiersprachen) nicht unterscheidet, sind die abstrakten Modelle allgemein gültig. Testfälle können so sehr schnell für verschiedenste Plattformen portiert werden.\\
Im vierten Schritt werden die erzeugten Testskripts ausgeführt. Bei der sogenannten \"Online-Execution\" wird der Testfall sofort nach Erzeugung auch ausgeführt. Das Tool, das den Testfall generiert, übernimmt also auch die Ausführung. Im selben Zug muss das Tool auch die Ergebnisse der Ausführung festhalten. Bei der ``Offline'' Erzeugung, wird der Testfall von einem Tool generiert und abgelegt. Anschließend führt ein anderes Werkzeug den Testfall aus und hält dessen Ergebnisse fest. So kann zur Ausführung, Analyse und Historisierung ein gewohntes oder selbst entwickeltes Tool verwendet werden.\\
Im letzten Schritt werden die Ergebnisse der Testfälle analysiert. Auch diesen Schritt teilen sich grundsätzlich alle Testmethoden. Den Detailgrad der Analyse bestimmt größtenteils das Tool, das zur Testausführung verwendet wurde. Dies reicht von einfachen Assertions, wie sie beispielsweise Selenium \footnote{Selenium Browser Automatisierungswerkzeug http://www.seleniumhq.org/} in seinem Grundumfang mitbringt, bis zu sehr detaillierten Berichten inklusive Zeitangaben, Screenshots und kontextuellen Informationen, wie beispielsweise die HP Applikations-Suite UFT \footnote{Testautomatisierungswerkzeug HP Unified Functional Tester http://www8.hp.com/ch/de/software-solutions/unified-functional-testing-automation/} es macht .

\subsection{Entscheidungshilfe für den Einsatz von MBT}
\label{sec:entscheidungshilfe}
In der Praxis stellt sich für jedes Software-Projektteam die Frage welche Teststrategie am effizientesten, in Bezug auf Qualität und Ressourcennutzung ist. Manuelles Testen gilt in der Industrie immer noch als das am häufigsten eingesetzte Verfahren \cite{guldali_starthilfe_2010}, aber deren Wirksamkeit mindert sich mit steigender Komplexität der zu testenden Software. Skriptbasierte Testautomatisierungstools kommen seit Jahren zum Einsatz. Durch die automatisierte Testausführung, wird der Testprozess schnell und wiederholbar. Verglichen mit manuellen Tests sind skriptbasierte Tests zeitsparender und weniger fehleranfällig. Gleichzeitig müssen skriptbasierte Tests gewartet werden, was einen nicht unerheblichen Ressourcenaufwand bedeuten kann.\\
Als Alternative dazu steht das modellbasierte Testen. Basierend auf \cite{guldali_starthilfe_2010} folgen acht Fragestellungen die zu einer Entscheidung bezüglich der Sinnhaftigkeit des Einsatzes von MBT führen sollen:

\todo{Grafik für Entscheidungshilfe (gerichteter Graph)}
\begin{itemize}
\item Wie komplex sind die Testbasis und die zu testende Funktionalität?
Die Komplexität des zu testenden Systems ist ein entscheidender Faktor, bei der Auswahl der passenden Teststrategie. Aus niedriger Komplexität oder allgemein wenig Funktionalität, resultieren wenig Testfälle, die mit manuellen Tests durchgeführt werden können. Diese erfordern wenig Planungsaufwand und können schnell ausgewertet werden. Bei steigendem Funktionsumfang kann eine skriptbasierte Ausführung der Testfälle sinnvoll sein. Außerdem kann modellbasiertes Testen die Generierung dieser Testfälle automatisieren.
\item Wie wichtig ist die Überdeckungsanalyse?
Im Software-Testing wird oft anhand der prozentualen Abdeckung des Quellcodes auf die Güte der Teststrategie geschlossen. Mittels skriptbasiertem Testen ist es aber nicht trivial festzustellen, welche Teile des Codes ein Testfall genau abdeckt. Mit MBT lässt sich anhand der Modellüberdeckung schneller feststellen welche Komponenten abgedeckt sind. Außerdem lassen sich Konzepte der Traceability (also der Verfolgbarkeit von Test zu Code) im MBT sehr einfach einführen. Modellbasierte Tests haben daher den nützlichen Nebeneffekt wie ein Vertrag, zwischen Requirement und tatsächlicher Funktionalität, zu funktionieren. Weil modellbasierte Tests oft einfach visuell dargestellt werden können, eignen sie sich auch zu Präsentationszwecken vor Kunden.
\item Wie häufig finden Änderungen in der Spezifikation statt? 
Unzufriedenheit mit skriptbasierten Tests entsteht oft aus teuren Wartungsarbeiten, die nötig werden sobald sich das zu testende System weiterentwickelt. Skriptbasierte Tests können nur zu einem gewissen Grad Änderungsunabhängig entwickelt werden. Gerade wenn das Softwareprojekt aus kurzen Entwicklungszyklen besteht (so wie es viele moderne agile Projekte sind), die viel Änderungspotenzial mit sich bringen, sollte MBT in Betracht gezogen werden.
\item Wie wichtig ist die Plattformunabhängigkeit der Testfälle?
Abhängig von der Testebene wo automatisierte Tests auf das System zugreifen, können skriptbasierte Tests nutzlos werden wenn beispielsweise der Austausch einer GUI-Bibliothek erfolgt. Da bei modellbasierten Tests eine strikte Trennung zwischen Testmodell und Adapter zum SUT gemacht wird, muss bei einem Plattformwechsel auch nur dieser Adapter angepasst werden. Auch bei industrieller Software die oft mittels dem Konzept der Software-Familien arbeitet, kann es von Vorteil sein wenn die eigentlichen Testkomponenten unabhängig von der Adapter-Logik bestehen.
\item Ist die Testbasis modellierbar?
Für die Modellierung des SUT ist eine Vielzahl von Notationen verfügbar. Zustandsbasierte und Ereignisbasierte \todo{Link zu einer Grundlagen section wo ich das erläutere} Notationsarten ermöglich die Modellierung sehr vieler funktionaler Eigenschaften. Wenn sich die Funktionalität der Testbasis aber nur unzureichend modellieren lässt, macht modellbasiertes Testen schlicht keinen Sinn.
\item Hat das Testteam Erfahrung mit Software-Modellierung? / Sind Modellierungskenntnisse im Testteam verfügbar?
Abhängig davon wie die Rollen im Projektteam verteilt sind, muss festgestellt werden ob Modellierungskenntnisse bei denjenigen vorhanden sind, die im weiteren Verlauf Testfälle erstellen und warten. Das Testteam muss deshalb möglicherweise geschult werden. Die Kosten dieser Schulungen, verglichen mit den Aufwänden für manuelles und skriptbasiertes Testen, können entscheidend für die Wahl von MBT sein.
\item Kann das Test-Orakel automatisiert werden?
Da beim modellbasierten Testen, Testfälle in der Regel automatisch generiert werden, sollen auch die erwarteten Testergebnisse modelliert oder in Form von Testdaten hinterlegbar und automatisch prüfbar sein. Falls die erwarteten Systemeigenschaften nicht modellierbar sein können, muss jeder Testfall manuell geprüft werden. Dieser Umstand mindert die Nützlichkeit von modellbasiertem Testen.
\item Ist die Bereitschaft für den Kauf und Einführung eines MBT-Werkzeugs vorhanden?
Eine Einführung von MBT ist immer auch mit Anschaffungskosten verbunden. Auf dem Markt sind verschiedenste Werkzeuge erhältlich \todo{Link zu Marktübersichts Section}. Weiters muss sich das gewählte Tool aber auch in bestehende Umgebungen integrieren lassen (was oft mit weiteren Kosten verbunden ist).
\end{itemize}

\subsubsection{Tool-Landschaft}
Wie auf dem Feld der skriptbasierten Testautomatisierung, ist die Auswahl an Tools zur Unterstützung von modellbasierten Tests vielfältig.Modellbasiertes Testen umfasst in der Regel mehrere Aktivitäten, für die jede Kombination aus passenden kommerziell erhältlichen Werkzeugen herangezogen werden können. Auch die marktführenden Tool-Hersteller haben begonnen ihre Testing Applikations-Suiten für MBT auszurüsten. 

\subsection{MBT Fallstudien}

Model-based Testing von Software wird seit mehr als 20 Jahren aktiv thematisiert, \cite{utting_practical_2007} sei es durch Forschung oder Industrie. Wie in den Leitlinien für den Einsatz von MBT in einem Projekt bereits erwähnt \ref{sec:entscheidungshilfe}, ist ein sinnvoller Einsatz nicht immer gegeben. Diese Leitlinien haben sich unter anderem, durch eben die folgenden Publikation und Fallstudien ergeben, sind aber keineswegs unveränderlich. Durch neue Erkenntnisse im laufenden Einsatz von MBT in den verschiedensten Projekten und durch die stetige Weiterentwicklung der beteiligten Technologien, entwickeln sie sich weiter.\\
Die folgenden Fallstudien geben einen Überblick darüber, wie MBT Methoden in den letzten Jahren eingesetzt wurden.

\paragraph{GUITAR: An innovative tool for automated testing of GUI-driven software \cite{nguyen_guitar:_2014}}Das von den Autoren entwickelte \textit{GUITAR} Framework wurde für modellbasiertes Oberflächentesting entwickelt. Das Werkzeug verhält sich dabei wie eine \textit{Learning Machine}. Soll heißen, es gibt eine endliche Anzahl von diskreten Parametern in das SUT (bedient das Programm) und beobachtet die Ergebnisse (wie sich das SUT verhält). Basierend auf diesen Ergebnisse generiert \textit{GUITAR} automatisch das Modell des SUT. Der Tester kann daraufhin Modifikationen am Modell vornehmen, bevor das eigentliche Testing beginnt.\\ 
In mehreren Fallstudien konnte \textit{GUITAR} Use-Cases nachstellen, in denen die korrekte Bedienung zu unerwarteten Abstürzen des SUT führte. Bedingt durch die geringe Intervention durch den Testentwickler, brachten die Tests eine gewisse Qualitätssteigerung mit wenig Ressourcenaufwand. Diese Methodik kann also hauptsächlich Aussagen über die Stabilität des SUT treffen, lässt aber kaum Schlüsse auf die funktionale Korrektheit zu.\\
Im Hinblick auf Applikationen mit vielen Datenfeldern, oder gar nicht standardisierten Eingabe- und Anzeigefeldern, ist diese Art des Testings nicht hinreichend, weil keinerlei Prüfung auf Korrektheit der angezeigten Daten stattfindet.

\paragraph{Industrial Application of Visual GUI Testing: Lessons learned \cite{alegroth_industrial_2014}}In dieser Publikation aus dem Jahr 2014, erproben Alégroth et al. in zwei groß angelegten Industriefallstudien ein \textit{Visual Testing} Werkzeug. Im Gegensatz zu weitverbreiteten Test-Tools, greift ihr Werkzeug nicht auf Widget-Ebene auf das SUT zu. Bei ihrem Ansatz werden Bitmaps von Oberflächen gemacht (Soll-Zustand) und beim Testdurchlauf mit neuen Bitmaps verglichen (Ist-Zustand). Das Werkzeug lässt feingradige Einstellungen zu, bis zu welchem Grad sich die Bitmaps unterscheiden dürfen um noch als korrekt zu gelten.\\
Die vorgestellte Technik soll manuelles Testen im späten Entwicklungszyklus (Akzeptanz- und Abnahmetests) ergänzen oder sogar ersetzen. Sie hat den Vorteil, dass kaum Aufwand bei der Wartung von Testfällen anfällt und fügt sich gut in eine Continuous Development Umgebung ein. Nachteilig ist aber die Tatsache, dass bei nicht optimaler Konfiguration viele Fehlerfälle (\textit{false negative's}) von Hand geprüft werden müssen.\\
Die Autoren kommen zum Schluss, dass \textit{Visual Testing} sehr wohl seine Daseinsberechtigung in der Qualitätssicherung von komplexer Industriesoftware hat. Sie halten fest, dass die vorgeschlagene Technik in beiden Fallstudien (Applikationen aus dem Bereich Militär und Avionik), genauso effektiv wie manuelle Tests funktioniert. Gleichzeitig ist der Ressourcenaufwand für die Wartung der Testfälle sehr niedrig und die Durchführungsgeschwindigkeit der Testfälle, verglichen mit manuellen Tests, um ein vielfaches höher. Sie halten aber ebenfalls fest, dass \textit{Visual Testing} Werkzeuge schon für den produktiven Einsatz geeignet sind aber noch viel Potenzial zur Verbesserung besteht (sie verwendeten Sikuli \footnote{VGT Test Tool - \url{http://www.sikuli.org/}}).


\paragraph{Microsoft’s Protocol Documentation Program: A Success Story for Model-Based Testing\cite{grieskamp_microsofts_2010}} Diese von Microsoft durchgeführte Fallstudie liefert exakte Zahlen zur Leistung von MBT im Projekt. Bei der Verfikation der Dokumentation von \textit{Client-Server} und \textit{Server-Server} Protokollen hat Microsoft MBT erstmals in einem großen und geschäftskritischen Umfeld eingesetzt. Die Ergebnisse deuten auf ein hohes Ressourceneinsparungspotenzial von MBT hin. Bei der Umsetzung von knapp zehntausend Test- Requirements mit MBT-Methoden ergab sich im Schnitt eine Dauer von 1,39 Personentagen/Requirement. Verglichen mit knapp neuntausend Requirements desselben Projekts, die mit traditionellen Methoden getestet wurden, die durchschnittlich 2,37 Personentage benötigen, ergab sich ein Produktivitätszugewinn von 42\%.

\paragraph{Model-Based Testing and Some Steps towards Test-Based Modelling\cite{tretmans_model-based_2011}} Die Autoren nehmen sich dem Problem Testing aus einem erfahrungsgemäß praxisnahen Blickwinkel an: Die initiale Hürde der Erstellung von Testmodellen, insbesondere auf Basis von schlechter oder nicht existenter Dokumentation. Test-based modelling, also das Generieren von Modellen anhand von bestehenden Testfällen, wird definiert. Für diesen Ansatz setzeen die Autoren \textit{Automata Learning} ein. Dabei handelt es sich um einen \textit{Machine Learning} Ansatz\cite{narendra_learning_1974}. Das Programm 

\subsection{Modellierungssprachen}
\subsubsection{Endliche Automaten (Finite-State-Machines)}
\label{sec:fsm}
Ein endlicher Automat (oder \textit{finite state machine}) ist eine Form der abstrakten Maschinen. Eine FSM erlaubt die Modellierung des Verhaltens einer Maschine, in diesem Fall eines Computer-Programms.\cite{wagner_modeling_2006}\\
Eine FSM ist immer in genauen \textbf{einem} Zustand. Sie besitzt, wie der Name schon sagt, eine endliche Anzahl von Zuständen. Zu jedem Zeitpunkt lässt sich die Maschine genau einem Zustand zuordnen. Zustände enthalten üblicherweise Informationen über die Vergangenheit, also wie die Maschine in den aktuellen Zustand gekommen ist. Diese Informationen müssen aber keineswegs vollständig sein. Aus einem aktuellen Zustand lässt sich nicht notwendigerweise reproduzieren welche Zustände die Maschine zuvor angenommen hat.\\

\paragraph{Aktionen}
Wenn eine FSM ihren Zustand ändert, spricht man von Zustandsübergängen. Weiters kann eine FSM zwischen Aktionen unterscheiden:
\begin{itemize}
\item Eingangsaktion (\textit{entry action}: Aktion wird bei Eintritt in einen Zustand durchgeführt
\item Ausgangsaktion (\textit{exit action}): Aktion wird bei Austritt aus einem Zustand durchgeführt
\item Eingabeaktion (\textit{input action}): Aktion wird basierend auf aktuellen Zustand und einem Eingabewert durchgeführt
\item Übergangsaktion (\textit{transition action}): Aktion wird beim Durchführen eines Übergangs durchgeführt
\end{itemize}

\paragraph{Zustände}
Eine FSM befindet sich zu jedem Zeitpunkt in genau einem Zustand. Mathematisch ist eine FSM folgendermaßen definiert: 

\begin{center}
$FSM := (Q, \Sigma, q_0, \delta, F)$
\end{center}

Wobei $Q$ die endliche Menge an Zuständen ist, $\Sigma$ ein endliches Eingabealphabet und $\delta$ die Übergangsfunktion. Von hoher Wichtigkeit im Kontext der Systemmodellierung sind die Elemente $q_0$ und $F$. Dabei handelt es sich bei $q_0$ um einen klar definierten Startzustand aus der Menge Q und bei $F \subseteq Q$ um eine Menge von Endzuständen. Meistens wird der Startzustand mit einem Pfeil oder einer Farbe gekennzeichnet. Die Endzustände werden meist mit einem doppelten Kreis (siehe Abbildung \ref{fig:fsm_example}) gekennzeichnet.

\begin{figure}[h] 
  \centering
     \includegraphics[width=0.5\textwidth]{figures/FSM_example.png}
  \caption{Beispielhafte FSM mit Eingangszustand $S_1$ (gekennzeichnet durch Pfeil von links) der gleichzeitig ein Endzustand ist (doppelter Kreis).}
  \label{fig:fsm_example}
\end{figure}

\subsubsection{B models}
\subsubsection{UML/ UML Testing Profile}
\paragraph{Test-Driven Testing mit UTP}
Businessapplikationen (unter anderem in den Bereichen Finanz-, Versicherungs- und Gesundheitswesen) basieren auf großen Datenbeständen. Diese wurden oft über Jahre und Jahrzehnte gesammelt und gespeichert. Zwischen den Datensätzen bestehen Abhängigkeit, die das Verhalten der Applikation stark beeinflussen. Solche Systeme werden als \textit{datengetrieben (data-driven)} bezeichnet. Das Testing von solchen Systemen ist dementsprechend gekennzeichnet durch die Verwendung von vielen, oft relationalen, Datensätzen. Die Praxis zeigt, dass sich die Datenstrukturen innerhalb eines Systems ändern und von der ursprünglichen Spezifikation abdriften. Es ist also von höchster Wichtigkeit, das Testdatenmangement angemessen zu designen um hohe Wartungsaufwände zu minimieren.\cite{baker_model-driven_2005}\\
Das UML Testing Profile bietet Unterstützung von datengetriebenen Tests in mehreren Formen.

\subparagraph{Wildcards in Ausprägungsspezifikationen}
UTP bietet vereinfachte Wildcards um zu spezifizieren, dass ein Attribut einen beliebigen Wert annehmen darf (annotiert mit \textit{?}) oder sogar keinen Wert haben darf (annotiert mit \textit{*}). Diese Wildcards können in sogenannten Ausprägungsspezifikationen (\textit{Instance Specifications} \footnote{Ausprägungsspezifikationen wurden im UML 2 Standard definiert \url{http://www.omg.org/spec/UML/2.4/} }) eingesetzt werden. Mit diesen kann die Existenz einer Entität innerhalb des modellierten Systems beschrieben werden. Instanzspezifikationen müssen ausdrücklich nicht vollständig sein, was dem Testfalldesigner zugute kommte, da oft nur wenige Attribute von Bedeutung sind. Solche Ausprägungsspezifikationen erlauben, die Definition von Testdaten ohne sie in Sequenzdiagramme `hart' zu codieren.

\begin{figure}[h] 
  \centering
     \includegraphics[width=0.7\textwidth]{figures/uml_instance.png}
  \caption{Eine UML Ausprägungsspezifikation. Sowohl eine Instanz der Klasse als auch eine Relation kann als Ausprägung dargestellt werden. (German Wikipedia user Gubaer [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC-BY-SA-3.0 (http://creativecommons.org/licenses/by-sa/3.0/)], via Wikimedia Commons)}
  \label{fig:uml_instance}
\end{figure}